{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_users_2.csv')\n",
    "test = pd.read_csv('data/test_users.csv')\n",
    "countries = pd.read_csv('data/countries.csv')\n",
    "user_demo = pd.read_csv('data/age_gender_bkts.csv')\n",
    "sessions = pd.read_csv('data/sessions.csv')\n",
    "#changing into datetime\n",
    "train.date_account_created = pd.to_datetime(train.date_account_created)\n",
    "train.timestamp_first_active = pd.to_datetime(train.timestamp_first_active, format = \"%Y%m%d%H%M%S\")\n",
    "train.date_first_booking = pd.to_datetime(train.date_first_booking)\n",
    "test.timestamp_first_active = pd.to_datetime(test.timestamp_first_active, format = \"%Y%m%d%H%M%S\")\n",
    "test.date_account_created = pd.to_datetime(test.date_account_created)\n",
    "\n",
    "train_destination = train.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unknowntrain = [i for i, j in enumerate(train.gender) if j == '-unknown-']\n",
    "train.loc[unknowntrain, 'gender'] = 'NA'\n",
    "unknowntest = [i for i, j in enumerate(test.gender) if j == '-unknown-']\n",
    "test.loc[unknowntest, 'gender'] = 'NA'\n",
    "\n",
    "#unknowntest = test.gender.index('-unknown-')\n",
    "#test.loc[unknowntest, 'gender'] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FEMALE', 'MALE', 'NA', 'OTHER'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sessions grouping by user\n",
    "\n",
    "#Group by user_id, aggregate by number of counts (counting device_type as it is never NA), \n",
    "#and total sum of elapsed time in seconds\n",
    "group_sessions = sessions.groupby(\"user_id\").agg({'device_type':'count', 'secs_elapsed':'sum'})\n",
    "#rename columns\n",
    "group_sessions.columns = ['sum_secs_elapsed', 'counts']\n",
    "#group by variable turns into index, I'm reseting the index and putting user_id back as a column\n",
    "group_sessions.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>sum_secs_elapsed</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00023iyk9l</td>\n",
       "      <td>867896.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0010k6l0om</td>\n",
       "      <td>586543.0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001wyh0pz8</td>\n",
       "      <td>282965.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028jgx1x1</td>\n",
       "      <td>297010.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002qnbzfs5</td>\n",
       "      <td>6487080.0</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  sum_secs_elapsed  counts\n",
       "0  00023iyk9l          867896.0      40\n",
       "1  0010k6l0om          586543.0      63\n",
       "2  001wyh0pz8          282965.0      90\n",
       "3  0028jgx1x1          297010.0      31\n",
       "4  002qnbzfs5         6487080.0     789"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_sessions.head() # to be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bucket all ages into format that user_demo is in for age\n",
    "def agebuckets(ages):\n",
    "    ageless =  [i for i in range(5,101,5)] # 5, 10, 15, 20...95, 100\n",
    "    buckets = ['%d-%d' %(i, i+4) for i in range(0,100,5)] # 0-4, 5-9, 10-14...90-94, 95-99\n",
    "    newlist = []\n",
    "    for i in range(len(ages)):\n",
    "        if math.isnan(ages[i]):\n",
    "            newlist.append('NA')\n",
    "        elif ages[i] <ageless[0]:\n",
    "            newlist.append(buckets[0])\n",
    "        elif ages[i] < ageless[1]:\n",
    "            newlist.append(buckets[1])\n",
    "        elif ages[i] < ageless[2]:\n",
    "            newlist.append(buckets[2])\n",
    "        elif ages[i] < ageless[3]:\n",
    "            newlist.append(buckets[3])\n",
    "        elif ages[i] < ageless[4]:\n",
    "            newlist.append(buckets[4])\n",
    "        elif ages[i] < ageless[5]:\n",
    "            newlist.append(buckets[5])\n",
    "        elif ages[i] < ageless[6]:\n",
    "            newlist.append(buckets[6])\n",
    "        elif ages[i] < ageless[7]:\n",
    "            newlist.append(buckets[7])\n",
    "        elif ages[i] < ageless[8]:\n",
    "            newlist.append(buckets[8])\n",
    "        elif ages[i] < ageless[9]:\n",
    "            newlist.append(buckets[9])\n",
    "        elif ages[i] < ageless[10]:\n",
    "            newlist.append(buckets[10])\n",
    "        elif ages[i] < ageless[11]:\n",
    "            newlist.append(buckets[11])\n",
    "        elif ages[i] < ageless[12]:\n",
    "            newlist.append(buckets[12]) \n",
    "        elif ages[i] < ageless[13]:\n",
    "            newlist.append(buckets[13]) \n",
    "        elif ages[i] < ageless[14]:\n",
    "            newlist.append(buckets[14])\n",
    "        elif ages[i] < ageless[15]:\n",
    "            newlist.append(buckets[15])\n",
    "        elif ages[i] < ageless[16]:\n",
    "            newlist.append(buckets[16])\n",
    "        elif ages[i] < ageless[17]:\n",
    "            newlist.append(buckets[17])\n",
    "        elif ages[i] < ageless[18]:\n",
    "            newlist.append(buckets[18])\n",
    "        elif ages[i] < ageless[19]:\n",
    "            newlist.append(buckets[19]) \n",
    "        else:\n",
    "            newlist.append('100+')\n",
    "    return newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      NaN\n",
       "1     38.0\n",
       "2     56.0\n",
       "3     42.0\n",
       "4     41.0\n",
       "5      NaN\n",
       "6     46.0\n",
       "7     47.0\n",
       "8     50.0\n",
       "9     46.0\n",
       "10    36.0\n",
       "11    47.0\n",
       "12     NaN\n",
       "13    37.0\n",
       "14    36.0\n",
       "15    33.0\n",
       "16     NaN\n",
       "17    31.0\n",
       "18     NaN\n",
       "19    29.0\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.age[0:20] #to be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.age = agebuckets(train.age)\n",
    "test.age = agebuckets(test.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        NA\n",
       "1     35-39\n",
       "2     55-59\n",
       "3     40-44\n",
       "4     40-44\n",
       "5        NA\n",
       "6     45-49\n",
       "7     45-49\n",
       "8     50-54\n",
       "9     45-49\n",
       "10    35-39\n",
       "11    45-49\n",
       "12       NA\n",
       "13    35-39\n",
       "14    35-39\n",
       "15    30-34\n",
       "16       NA\n",
       "17    30-34\n",
       "18       NA\n",
       "19    25-29\n",
       "Name: age, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.age[0:20] # to be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def timedif(L1, L2):\n",
    "    timediflist = []\n",
    "    for i in range(len(L1)):\n",
    "        try:\n",
    "            if (L1[i]-L2[i]).days <= -1:#datetime.timedelta(days=0):\n",
    "                timediflist.append('before')\n",
    "            elif (L1[i]-L2[i]).days ==0: #datetime.timedelta(days=1):\n",
    "                timediflist.append('same day')\n",
    "            else:\n",
    "                timediflist.append('greater 1 day')\n",
    "        except:\n",
    "            timediflist.append('NB')\n",
    "            \n",
    "    return timediflist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NB', 'before', 'greater 1 day', 'same day'], \n",
       "      dtype='|S13')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(timedif(train.date_first_booking, train.date_account_created)) #testing to be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NB'], \n",
       "      dtype='|S2')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(timedif(test.date_first_booking, test.date_account_created)) #testing to be deleted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NB', 'before', 'greater 1 day', 'same day'], \n",
       "      dtype='|S13')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(timedif(train.date_first_booking, train.timestamp_first_active)) # testing to be deleted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NB'], \n",
       "      dtype='|S2')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(timedif(test.date_first_booking, test.timestamp_first_active)) # testing to be deleted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adding time lag columns\n",
    "train['lag_account_created'] = timedif(train.date_first_booking, train.date_account_created)\n",
    "train['lag_first_active'] = timedif(train.date_first_booking, train.timestamp_first_active)\n",
    "train['lag_account_created_first_active'] = timedif(train.date_account_created, train.timestamp_first_active)\n",
    "test['lag_account_created_first_active'] = timedif(test.date_account_created, test.timestamp_first_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bookings(L1, L2, L3, L4):\n",
    "    timediflist = []\n",
    "    for i in range(len(L1)):\n",
    "        if L1[i] == 'same day' or L2[i] == 'same day':\n",
    "            timediflist.append('early')\n",
    "        elif L1[i] == 'before' and L2[i] == 'before' and L3[i] == 'same day':\n",
    "            timediflist.append('early')\n",
    "        elif L1[i] == 'greater 1 day' and L2[i] == 'greater 1 day':\n",
    "            timediflist.append('waited')\n",
    "        elif L1[i] == 'greater 1 day' and L2[i] == 'before':\n",
    "            timediflist.append('waited')\n",
    "        elif L1[i] == 'before' and L2[i] == 'greater 1 day':\n",
    "            timediflist.append('waited')\n",
    "        elif L1[i] == 'before' and L2[i] == 'before' and L3[i] == 'greater 1 day':\n",
    "            timediflist.append('waited')\n",
    "        elif L4[i] == 'NDF':\n",
    "            timediflist.append('NB')\n",
    "        else:\n",
    "            timediflist.append('NA')\n",
    "\n",
    "            \n",
    "    return timediflist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "booking = bookings(train.lag_account_created, train.lag_first_active, train.lag_account_created_first_active, train.country_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['bookings'] = booking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NB',\n",
       " 'NB',\n",
       " 11264.0,\n",
       " 2458.8000000000002,\n",
       " 'NA',\n",
       " 'NA',\n",
       " 10659.0,\n",
       " 10659.0,\n",
       " 11413.0,\n",
       " 'NA']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#given the train data gender, age, and country_desination produce the corresponding population in thousands\n",
    "population_in_thous = []\n",
    "for i in range(train.shape[0]):\n",
    "    if train.country_destination[i] == 'NDF':\n",
    "        population_in_thous.append('NB')    \n",
    "    elif train.gender[i] == 'NA' or train.age[i] == 'NA' or train.gender[i] == 'nan': \n",
    "        population_in_thous.append('NA')\n",
    "    elif train.gender[i] == 'OTHER':\n",
    "        population_in_thous.append(0)  \n",
    "    elif train.country_destination[i] == 'other':\n",
    "        gendersi = user_demo.loc[user_demo.gender == train.gender[i].lower(),:] \n",
    "        ages = gendersi.loc[gendersi.age_bucket == train.age[i], :]\n",
    "        ages = list(map(lambda x: float(x), ages.population_in_thousands))\n",
    "        population_in_thous.append(np.mean(ages))\n",
    "    else:\n",
    "        genders = user_demo.loc[user_demo.gender == train.gender[i].lower(),:] \n",
    "        dests = genders.loc[genders.country_destination == train.country_destination[i] ,:]    \n",
    "        population_in_thous.append(float((dests.loc[dests.age_bucket == train.age[i], 'population_in_thousands'])))\n",
    "        \n",
    "population_in_thous[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merging gender age bucket with train data\n",
    "train['population_in_thousands'] = population_in_thous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id date_account_created timestamp_first_active date_first_booking  \\\n",
      "0  gxn3p5htnn           2010-06-28    2009-03-19 04:32:55                NaT   \n",
      "1  820tgsjxq7           2011-05-25    2009-05-23 17:48:09                NaT   \n",
      "2  4ft3gnwmtx           2010-09-28    2009-06-09 23:12:47         2010-08-02   \n",
      "3  bjjt8pjhuk           2011-12-05    2009-10-31 06:01:29         2012-09-08   \n",
      "4  87mebub9p4           2010-09-14    2009-12-08 06:11:05         2010-02-18   \n",
      "\n",
      "   gender    age signup_method  signup_flow language affiliate_channel  \n",
      "0      NA     NA      facebook            0       en            direct  \n",
      "1    MALE  35-39      facebook            0       en               seo  \n",
      "2  FEMALE  55-59         basic            3       en            direct  \n",
      "3  FEMALE  40-44      facebook            0       en            direct  \n",
      "4      NA  40-44         basic            0       en            direct  \n",
      "  affiliate_provider first_affiliate_tracked signup_app first_device_type  \\\n",
      "0             direct               untracked        Web       Mac Desktop   \n",
      "1             google               untracked        Web       Mac Desktop   \n",
      "2             direct               untracked        Web   Windows Desktop   \n",
      "3             direct               untracked        Web       Mac Desktop   \n",
      "4             direct               untracked        Web       Mac Desktop   \n",
      "\n",
      "  first_browser country_destination lag_account_created lag_first_active  \\\n",
      "0        Chrome                 NDF                  NB               NB   \n",
      "1        Chrome                 NDF                  NB               NB   \n",
      "2            IE                  US              before    greater 1 day   \n",
      "3       Firefox               other       greater 1 day    greater 1 day   \n",
      "4        Chrome                  US              before    greater 1 day   \n",
      "\n",
      "  lag_account_created_first_active bookings population_in_thousands  \\\n",
      "0                    greater 1 day       NB                      NB   \n",
      "1                    greater 1 day       NB                      NB   \n",
      "2                    greater 1 day   waited                   11264   \n",
      "3                    greater 1 day   waited                  2458.8   \n",
      "4                    greater 1 day   waited                      NA   \n",
      "\n",
      "   sum_secs_elapsed  counts  \n",
      "0               NaN     NaN  \n",
      "1               NaN     NaN  \n",
      "2               NaN     NaN  \n",
      "3               NaN     NaN  \n",
      "4               NaN     NaN  \n"
     ]
    }
   ],
   "source": [
    "#merging with grouped sessions and countries, **note most of training data is not in sessions. see below \n",
    "test = pd.merge(test, group_sessions, left_on='id', right_on ='user_id', how='left')\n",
    "train = pd.merge(train, group_sessions, left_on='id', right_on ='user_id', how='left')\n",
    "test = test.drop('user_id', 1)\n",
    "train = train.drop('user_id', 1)\n",
    "print train.iloc[0:5, 0:10] #to be deleted?\n",
    "print train.iloc[0:5, 10:]  # to be deleted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-68cc10619a6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#train.loc[NDFtrain, 'destination_km2'] = 'NB'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#train.loc[NDFtrain, 'destination_language '] = 'NB'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;31m#rain.loc[NDFtrain, 'language_levenshtein_distance'] = 'NB'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#to be deleted?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# to be deleted?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "#NDFtrain = [i for i, j in enumerate(train.country_destination) if j == 'NDF']\n",
    "#train.loc[NDFtrain, 'lat_destination'] = 'NB'\n",
    "#train.loc[NDFtrain, 'lng_destination'] = 'NB'\n",
    "#train.loc[NDFtrain, 'distance_km'] = 'NB'\n",
    "#train.loc[NDFtrain, 'destination_km2'] = 'NB'\n",
    "#train.loc[NDFtrain, 'destination_language '] = 'NB'\n",
    "#t#rain.loc[NDFtrain, 'language_levenshtein_distance'] = 'NB'\n",
    "print train.iloc[0:5, 0:10] #to be deleted?\n",
    "print train.iloc[0:5, 10:]  # to be deleted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train.iloc[0:5,0:10]\n",
    "print train.iloc[0:5,10:20]\n",
    "print train.iloc[0:5,20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#delete all  but one time row now that we have lag times?\n",
    "#remove either train['lag_account_created'] or train['lag_first_active'] to take into account leakage\n",
    "#note country destination still in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.to_csv('train_starting.csv')\n",
    "test.to_csv('test_starting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#appendix showing the missinginess of the training ids in the sessions csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strgroupids = ' '.join(group_sessions.user_id) #making a huge string of all the users ids in group_sesssions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61668"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(lambda x: strgroupids.find(x) != -1, test.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73815"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(lambda x: strgroupids.find(x) != -1, train.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape  (62096, 15)\n",
      "train shape (213451, 16)\n",
      "# test ids in sessions/#test ids 0.993107446534\n",
      "# train ids in sessions/#train ids 0.345817072771\n"
     ]
    }
   ],
   "source": [
    "print 'test shape ', test.shape\n",
    "print 'train shape', train.shape\n",
    "\n",
    "print '# test ids in sessions/#test ids', 61668.0/62096\n",
    "print '# train ids in sessions/#train ids', 73815.0/213451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train_starting.csv')\n",
    "test = pd.read_csv('test_starting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-0.4a30.tar.gz (753kB)\n",
      "\u001b[K    100% |████████████████████████████████| 757kB 930kB/s \n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): numpy in /usr/local/lib/python2.7/site-packages (from xgboost)\n",
      "Requirement already satisfied (use --upgrade to upgrade): scipy in /usr/local/lib/python2.7/site-packages (from xgboost)\n",
      "Building wheels for collected packages: xgboost\n",
      "  Running setup.py bdist_wheel for xgboost ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/YannickMac/Library/Caches/pip/wheels/d3/43/37/f902e214730441ba23bfc73621fad90dd6634e7fb34090a804\n",
      "Successfully built xgboost\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.4a30\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lists = list(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lists.remove('country_destination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'id',\n",
       " 'date_account_created',\n",
       " 'timestamp_first_active',\n",
       " 'date_first_booking',\n",
       " 'gender',\n",
       " 'age',\n",
       " 'signup_method',\n",
       " 'signup_flow',\n",
       " 'language',\n",
       " 'affiliate_channel',\n",
       " 'affiliate_provider',\n",
       " 'first_affiliate_tracked',\n",
       " 'signup_app',\n",
       " 'first_device_type',\n",
       " 'first_browser',\n",
       " 'lag_account_created',\n",
       " 'lag_first_active',\n",
       " 'lag_account_created_first_active',\n",
       " 'bookings',\n",
       " 'population_in_thousands',\n",
       " 'sum_secs_elapsed',\n",
       " 'counts',\n",
       " 'lat_destination',\n",
       " 'lng_destination',\n",
       " 'distance_km',\n",
       " 'destination_km2',\n",
       " 'destination_language ',\n",
       " 'language_levenshtein_distance']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train.loc[:,lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = train.loc[:, 'country_destination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AttributeError: \"'DMatrix' object has no attribute 'handle'\" in <bound method DMatrix.__del__ of <xgboost.core.DMatrix object at 0x116359a90>> ignored\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-30e6d59efafd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mnum_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    217\u001b[0m         data, feature_names, feature_types = _maybe_pandas_data(data,\n\u001b[1;32m    218\u001b[0m                                                                 \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                                                                 feature_types)\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_pandas_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[0;34m(data, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mdata_dtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPANDAS_DTYPE_MAPPER\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_dtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataFrame.dtypes for data must be int, float or bool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "params = {}\n",
    "params[\"objective\"] = \"multi:softmax\"\n",
    "params[\"eta\"] = 0.005\n",
    "params[\"min_child_weight\"] = 6\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 1\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 9\n",
    "params['eval_metric'] = 'ndcg@5'\n",
    "params['nthread'] = 4\n",
    "params['missing'] = \"NA\"\n",
    "plst = list(params.items())\n",
    "\n",
    "dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "\n",
    "num_round = 5\n",
    "model = xgb.train(plst, dtrain, num_round)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
